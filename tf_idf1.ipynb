{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim import corpora, models, similarities\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t0=time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets=[['human', 'interface', 'computer'],\n",
    " ['survey', 'user', 'computer', 'system', 'response', 'time'],\n",
    " ['eps', 'user', 'interface', 'system'],\n",
    " ['system', 'human', 'system', 'eps'],\n",
    " ['user', 'response', 'time'],\n",
    " ['trees'],\n",
    " ['graph', 'trees'],\n",
    " ['graph', 'minors', 'trees'],\n",
    " ['graph', 'minors', 'survey']] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's start with a raw corpus :<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(\"Let's start with a raw corpus :%s\"%type(tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "dictionary = corpora.Dictionary(tweets)\n",
    "dictionary.save('/tmp/tweets.dict') # store the dictionary, for future reference\n",
    "print(len(dictionary))\n",
    "#print(\"We create a dictionary, an index of all unique values: %s\"%type(dictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 'time')\n",
      "(3, 'response')\n",
      "(1, 'interface')\n",
      "(2, 'human')\n",
      "(0, 'computer')\n",
      "(11, 'minors')\n",
      "(8, 'eps')\n",
      "(4, 'system')\n",
      "(7, 'survey')\n",
      "(6, 'user')\n",
      "(9, 'trees')\n",
      "(10, 'graph')\n"
     ]
    }
   ],
   "source": [
    "for k in dictionary.items():\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 1), (2, 1)], [(0, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1)], [(1, 1), (4, 1), (6, 1), (8, 1)], [(2, 1), (4, 2), (8, 1)], [(3, 1), (5, 1), (6, 1)], [(9, 1)], [(9, 1), (10, 1)], [(9, 1), (10, 1), (11, 1)], [(7, 1), (10, 1), (11, 1)]]\n",
      "Then convert convert tokenized documents to vectors: <class 'list'>\n",
      "Save the vectorized corpus as a .mm file\n",
      "[[(0, 1), (1, 1), (2, 1)], [(0, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1)], [(1, 1), (4, 1), (6, 1), (8, 1)], [(2, 1), (4, 2), (8, 1)], [(3, 1), (5, 1), (6, 1)], [(9, 1)], [(9, 1), (10, 1)], [(9, 1), (10, 1), (11, 1)], [(7, 1), (10, 1), (11, 1)]]\n"
     ]
    }
   ],
   "source": [
    "raw_corpus = [dictionary.doc2bow(t) for t in tweets]\n",
    "print(raw_corpus)\n",
    "print(\"Then convert convert tokenized documents to vectors: %s\"% type(raw_corpus))\n",
    "corpora.MmCorpus.serialize('/tmp/tweets.mm', raw_corpus) # store to disk\n",
    "print(\"Save the vectorized corpus as a .mm file\")\n",
    "print(raw_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary.load('/tmp/tweets.dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = corpora.MmCorpus('/tmp/tweets.mm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MmCorpus(9 documents, 12 features, 28 non-zero entries)\n"
     ]
    }
   ],
   "source": [
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf = models.TfidfModel(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 2.1699250014423126,\n",
       " 1: 2.1699250014423126,\n",
       " 2: 2.1699250014423126,\n",
       " 3: 2.1699250014423126,\n",
       " 4: 1.5849625007211563,\n",
       " 5: 2.1699250014423126,\n",
       " 6: 1.5849625007211563,\n",
       " 7: 2.1699250014423126,\n",
       " 8: 2.1699250014423126,\n",
       " 9: 1.5849625007211563,\n",
       " 10: 1.5849625007211563,\n",
       " 11: 2.1699250014423126}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.idfs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpus_tfidf = tfidf[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.5773502691896257), (1, 0.5773502691896257), (2, 0.5773502691896257)]\n",
      "[(0, 0.44424552527467476), (3, 0.44424552527467476), (4, 0.3244870206138555), (5, 0.44424552527467476), (6, 0.3244870206138555), (7, 0.44424552527467476)]\n",
      "[(1, 0.5710059809418182), (4, 0.4170757362022777), (6, 0.4170757362022777), (8, 0.5710059809418182)]\n",
      "[(2, 0.49182558987264147), (4, 0.7184811607083769), (8, 0.49182558987264147)]\n",
      "[(3, 0.6282580468670046), (5, 0.6282580468670046), (6, 0.45889394536615247)]\n",
      "[(9, 1.0)]\n",
      "[(9, 0.7071067811865475), (10, 0.7071067811865475)]\n",
      "[(9, 0.5080429008916749), (10, 0.5080429008916749), (11, 0.695546419520037)]\n",
      "[(7, 0.6282580468670046), (10, 0.45889394536615247), (11, 0.6282580468670046)]\n"
     ]
    }
   ],
   "source": [
    "for doc in corpus_tfidf:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We get a similarity matrix for all documents in the corpus <class 'numpy.ndarray'>\n",
      "[[ 0.99999994  0.25648525  0.32967046  0.28395563  0.          0.          0.\n",
      "   0.          0.        ]\n",
      " [ 0.25648525  1.          0.27067134  0.23313783  0.70710683  0.          0.\n",
      "   0.          0.27910084]\n",
      " [ 0.32967046  0.27067134  1.          0.58049643  0.19139352  0.          0.\n",
      "   0.          0.        ]\n",
      " [ 0.28395563  0.23313783  0.58049643  1.          0.          0.          0.\n",
      "   0.          0.        ]\n",
      " [ 0.          0.70710683  0.19139352  0.          1.          0.          0.\n",
      "   0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          1.\n",
      "   0.70710677  0.50804287  0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.70710677\n",
      "   0.99999994  0.71848112  0.32448703]\n",
      " [ 0.          0.          0.          0.          0.          0.50804287\n",
      "   0.71848112  1.          0.67012048]\n",
      " [ 0.          0.27910084  0.          0.          0.          0.\n",
      "   0.32448703  0.67012048  1.        ]]\n"
     ]
    }
   ],
   "source": [
    "index = similarities.MatrixSimilarity(tfidf[corpus])\n",
    "#print \"We compute similarities from the TF-IDF corpus : %s\"%type(index)\n",
    "index.save('/tmp/deerwester.index')\n",
    "index = similarities.MatrixSimilarity.load('/tmp/deerwester.index')\n",
    "\n",
    "sims = index[corpus_tfidf]\n",
    "print(\"We get a similarity matrix for all documents in the corpus %s\"% type(sims))\n",
    "#print \n",
    "#print(\"Done in %.3fs\"%(time()-t0))\n",
    "print(sims)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.99999994,  0.25648525,  0.32967046,  0.28395563,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.25648525,  1.        ,  0.27067134,  0.23313783,  0.70710683,\n",
       "         0.        ,  0.        ,  0.        ,  0.27910084],\n",
       "       [ 0.32967046,  0.27067134,  1.        ,  0.58049643,  0.19139352,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.28395563,  0.23313783,  0.58049643,  1.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.70710683,  0.19139352,  0.        ,  1.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         1.        ,  0.70710677,  0.50804287,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.70710677,  0.99999994,  0.71848112,  0.32448703],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.50804287,  0.71848112,  1.        ,  0.67012048],\n",
       "       [ 0.        ,  0.27910084,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.32448703,  0.67012048,  1.        ]], dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.get_similarities()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 9)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sims.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize,word_tokenize,regexp_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def regex_token(list):\n",
    "    words = []    \n",
    "    words_2 = regexp_tokenize(list, pattern=r'\\w+')\n",
    "    words.append(words_2)\n",
    "    return words_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def query_of_similarity(t):\n",
    "    #text = regex_token(t)\n",
    "    s = sent_tokenize(t)\n",
    "    text = []\n",
    "    for sent in s:\n",
    "        text.append(word_tokenize(sent))\n",
    "    print(text)\n",
    "    dictionary2 = corpora.Dictionary(text)\n",
    "    dictionary2.save('/tmp/query.dict') # store the dictionary, for future reference\n",
    "    raw_corpus2 = [dictionary.doc2bow(t) for t in text]\n",
    "    corpora.MmCorpus.serialize('/tmp/rawcorpus2.mm', raw_corpus2) # store to disk\n",
    "    dictionary2 = corpora.Dictionary.load('/tmp/query.dict')\n",
    "    corpus2 = corpora.MmCorpus('/tmp/rawcorpus2.mm')\n",
    "    r = index.get_similarities(tfidf[corpus2])\n",
    "    print(r)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['user', 'system', '.'], ['computer']]\n",
      "[[ 0.          0.45889395  0.58983415  0.50804293  0.32448703  0.          0.\n",
      "   0.          0.        ]\n",
      " [ 0.57735026  0.44424552  0.          0.          0.          0.          0.\n",
      "   0.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "query_of_similarity(\"user system. computer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
